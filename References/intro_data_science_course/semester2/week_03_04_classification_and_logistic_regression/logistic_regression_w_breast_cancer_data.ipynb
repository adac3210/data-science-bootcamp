{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../predictioNN_Logo_JPG(72).jpg\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Logistic Regression with Breast Cancer Data\n",
    "\n",
    "### Introduction to Data Science\n",
    "#### Last Updated: February 27, 2023\n",
    "---  \n",
    "\n",
    "### SOURCES\n",
    "- [Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "### OBJECTIVES\n",
    "- Implement logistic regression using `sklearn`\n",
    "- Use the sigmoid function to compute the predicted probability\n",
    "- Compute binary classification metrics\n",
    "\n",
    "### CONCEPTS\n",
    "- logistic regression\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Logistic Regression with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We worked with the sigmoid function for computing probabilities of a binary outcome.  \n",
    "Logistic regression is a model that does these things:\n",
    "- Use a linear combination of predictors as input, equal to: $\\beta_0 + \\beta_1 X_1 + ... + \\beta_n X_n$\n",
    "- Feed the input into the sigmoid function (a.k.a. logistic function)\n",
    "- Estimate the parameters to minimize error\n",
    "- Output a probability estimate of the outcome\n",
    "\n",
    "Now we will work with the Wisconsin Breast Cancer Dataset to predict if a cell is benign ('B') or malignant ('M'). \n",
    "\n",
    "The dataset was sourced here:  \n",
    "https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../datasets/wdbc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis     f1     f2      f3      f4       f5       f6      f7  \\\n",
       "0    842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        f8  ...    f21    f22     f23     f24     f25     f26     f27     f28  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "      f29      f30  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the Fields**\n",
    "\n",
    "`id` - unique identifier for each subject  \n",
    "`diagnosis` - target variable indicating if cell is malignant or benign  \n",
    "`f1-f30` - cell measurement variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "\n",
    "The `diagnosis` field is the target variable. It needs to be converted to values of 0 and 1.  \n",
    "We can make malignant = 1, benign = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis     f1     f2      f3      f4       f5       f6      f7  \\\n",
      "0    842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
      "1    842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
      "2  84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
      "3  84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
      "4  84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
      "\n",
      "        f8  ...    f22     f23     f24     f25     f26     f27     f28  \\\n",
      "0  0.14710  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
      "1  0.07017  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
      "2  0.12790  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
      "3  0.10520  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
      "4  0.10430  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
      "\n",
      "      f29      f30  target  \n",
      "0  0.4601  0.11890       1  \n",
      "1  0.2750  0.08902       1  \n",
      "2  0.3613  0.08758       1  \n",
      "3  0.6638  0.17300       1  \n",
      "4  0.2364  0.07678       1  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "         id diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
      "564  926424         M  21.56  22.39  142.00  1479.0  0.11100  0.11590   \n",
      "565  926682         M  20.13  28.25  131.20  1261.0  0.09780  0.10340   \n",
      "566  926954         M  16.60  28.08  108.30   858.1  0.08455  0.10230   \n",
      "567  927241         M  20.60  29.33  140.10  1265.0  0.11780  0.27700   \n",
      "568   92751         B   7.76  24.54   47.92   181.0  0.05263  0.04362   \n",
      "\n",
      "          f7       f8  ...    f22     f23     f24      f25      f26     f27  \\\n",
      "564  0.24390  0.13890  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
      "565  0.14400  0.09791  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
      "566  0.09251  0.05302  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
      "567  0.35140  0.15200  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
      "568  0.00000  0.00000  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
      "\n",
      "        f28     f29      f30  target  \n",
      "564  0.2216  0.2060  0.07115       1  \n",
      "565  0.1628  0.2572  0.06637       1  \n",
      "566  0.1418  0.2218  0.07820       1  \n",
      "567  0.2650  0.4087  0.12400       1  \n",
      "568  0.0000  0.2871  0.07039       0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the data, using f1 and f2 as predictors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['f1','f2']].values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into training set, test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, train_size = 0.6, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print some of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tr: \n",
      " [[19.21 18.57]\n",
      " [19.59 25.  ]\n",
      " [10.29 27.61]\n",
      " [13.85 19.6 ]\n",
      " [12.47 18.6 ]]\n",
      "\n",
      "y_tr: \n",
      " [1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('x_tr: \\n', x_tr[:5,:])\n",
    "print('')\n",
    "print('y_tr: \\n', y_tr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the logistic regression model**\n",
    "\n",
    "Turn off penality for large parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='none').fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the model coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.10417367, 0.22893814]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the model intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.75395288])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the coefficient on f1 and f2 is 1.10417367 and 0.22893814, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict the Cell Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 1 0 1 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# store the predictions for all subjects in a new column\n",
    "df['label_predicted'] = model.predict(X)\n",
    "\n",
    "# print the predictions\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter the dataframe to show subjects where the prediction matches the target. These are correct predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>target</th>\n",
       "      <th>label_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
       "0      842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760   \n",
       "1      842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864   \n",
       "2    84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990   \n",
       "4    84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
       "6      844359         M  18.25  19.98  119.60  1040.0  0.09463  0.10900   \n",
       "..        ...       ...    ...    ...     ...     ...      ...      ...   \n",
       "564    926424         M  21.56  22.39  142.00  1479.0  0.11100  0.11590   \n",
       "565    926682         M  20.13  28.25  131.20  1261.0  0.09780  0.10340   \n",
       "566    926954         M  16.60  28.08  108.30   858.1  0.08455  0.10230   \n",
       "567    927241         M  20.60  29.33  140.10  1265.0  0.11780  0.27700   \n",
       "568     92751         B   7.76  24.54   47.92   181.0  0.05263  0.04362   \n",
       "\n",
       "          f7       f8  ...     f23     f24      f25      f26     f27     f28  \\\n",
       "0    0.30010  0.14710  ...  184.60  2019.0  0.16220  0.66560  0.7119  0.2654   \n",
       "1    0.08690  0.07017  ...  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n",
       "2    0.19740  0.12790  ...  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n",
       "4    0.19800  0.10430  ...  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n",
       "6    0.11270  0.07400  ...  153.20  1606.0  0.14420  0.25760  0.3784  0.1932   \n",
       "..       ...      ...  ...     ...     ...      ...      ...     ...     ...   \n",
       "564  0.24390  0.13890  ...  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n",
       "565  0.14400  0.09791  ...  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n",
       "566  0.09251  0.05302  ...  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n",
       "567  0.35140  0.15200  ...  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n",
       "568  0.00000  0.00000  ...   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n",
       "\n",
       "        f29      f30  target  label_predicted  \n",
       "0    0.4601  0.11890       1                1  \n",
       "1    0.2750  0.08902       1                1  \n",
       "2    0.3613  0.08758       1                1  \n",
       "4    0.2364  0.07678       1                1  \n",
       "6    0.3063  0.08368       1                1  \n",
       "..      ...      ...     ...              ...  \n",
       "564  0.2060  0.07115       1                1  \n",
       "565  0.2572  0.06637       1                1  \n",
       "566  0.2218  0.07820       1                1  \n",
       "567  0.4087  0.12400       1                1  \n",
       "568  0.2871  0.07039       0                0  \n",
       "\n",
       "[507 rows x 34 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label_predicted'] == df['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict the Probability of Each Cell Type in Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00893677, 0.99106323],\n",
       "       [0.00135816, 0.99864184],\n",
       "       [0.95568155, 0.04431845],\n",
       "       [0.7259081 , 0.2740919 ],\n",
       "       [0.93858145, 0.06141855]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_tr)[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for the first subject, the probability of a benign cell is 0.99106323\n",
    "The probability of a malignant cell is 0.99018766\n",
    "\n",
    "Since the malignant probability is greater than the default threshold of 0.5, the predicted cell type is 1 (malignant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Positive Probabilities**\n",
    "\n",
    "It can be useful to extract the probabilities of the positive label for each subject.  \n",
    "This can be done by extracting the second index across all rows like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.91063235e-01, 9.98641837e-01, 4.43184472e-02, 2.74091901e-01,\n",
       "       6.14185475e-02, 6.67955381e-01, 5.42011809e-04, 9.98889274e-01,\n",
       "       2.88187797e-02, 1.95646879e-04, 1.92967094e-01, 9.71140017e-01,\n",
       "       9.97634959e-01, 7.26186116e-01, 1.80975222e-01, 9.63717313e-01,\n",
       "       9.19852744e-01, 9.99284578e-01, 5.28076017e-01, 6.07927249e-04,\n",
       "       3.83881847e-02, 2.65537551e-01, 4.02584320e-02, 9.93553613e-01,\n",
       "       4.07013743e-02, 9.74593533e-01, 9.96214999e-01, 2.53165292e-01,\n",
       "       9.99693326e-01, 9.55925072e-02, 9.99761096e-01, 7.01868445e-01,\n",
       "       4.28926102e-02, 9.74549370e-01, 2.64989478e-02, 1.58036169e-01,\n",
       "       1.24316415e-01, 3.73227274e-02, 5.60511843e-02, 3.73205023e-01,\n",
       "       6.85587717e-01, 5.90320061e-01, 9.60803243e-03, 2.33751855e-02,\n",
       "       9.86887680e-01, 9.54189030e-01, 9.99686449e-01, 6.68022413e-03,\n",
       "       7.44899193e-02, 1.61047431e-02, 2.47894574e-02, 9.79192148e-01,\n",
       "       9.77291608e-03, 7.41325736e-01, 8.69464391e-02, 8.15890955e-01,\n",
       "       9.97593399e-01, 1.29947508e-01, 8.10378433e-03, 7.15366370e-01,\n",
       "       9.97531623e-01, 8.72713971e-01, 7.50578335e-02, 2.63096493e-01,\n",
       "       9.92069773e-01, 4.45646586e-01, 2.30265094e-01, 9.05382503e-01,\n",
       "       4.26685508e-02, 4.21954189e-01, 4.95456628e-03, 9.67817196e-01,\n",
       "       9.97863178e-01, 9.93516799e-01, 1.89881383e-02, 7.77009700e-01,\n",
       "       3.55947787e-03, 1.32170923e-03, 3.40798388e-03, 2.24615812e-02,\n",
       "       2.30863419e-03, 9.99906855e-01, 2.08649293e-01, 9.99103324e-01,\n",
       "       1.50846554e-01, 9.83324986e-01, 3.16409387e-03, 8.90113167e-01,\n",
       "       6.91952235e-02, 9.79548339e-01, 2.20936878e-01, 8.06615057e-02,\n",
       "       4.09753098e-02, 7.66160204e-01, 4.88266744e-01, 3.04686934e-02,\n",
       "       8.83365278e-01, 1.07016125e-01, 1.56681010e-03, 5.68326691e-03,\n",
       "       1.92120037e-01, 2.77422723e-01, 1.23599207e-01, 2.49771177e-01,\n",
       "       9.78958519e-01, 9.99999502e-01, 6.74617175e-02, 3.91865628e-02,\n",
       "       6.58582916e-02, 1.69786765e-02, 9.99616919e-01, 5.55635282e-04,\n",
       "       1.13541885e-01, 9.98940153e-01, 1.83580353e-01, 4.00958972e-03,\n",
       "       1.94362665e-02, 2.05746572e-02, 3.58868725e-02, 3.83947468e-02,\n",
       "       9.99644122e-01, 1.78314960e-01, 8.72824821e-01, 1.10028156e-01,\n",
       "       8.82965897e-01, 6.16784548e-02, 2.08431813e-01, 8.15553774e-01,\n",
       "       3.19020854e-02, 5.38898266e-02, 7.92683033e-01, 3.46521730e-02,\n",
       "       5.31285696e-03, 9.98264197e-01, 1.65990977e-02, 8.53545660e-03,\n",
       "       5.63930685e-02, 9.89590446e-01, 4.81591694e-01, 9.98856522e-01,\n",
       "       5.78992550e-03, 1.84873227e-03, 9.99623831e-01, 1.78554943e-01,\n",
       "       4.98181393e-01, 1.80653669e-01, 9.98785813e-01, 2.08889225e-01,\n",
       "       5.84856872e-02, 7.47517362e-02, 3.90205078e-01, 2.15623739e-01,\n",
       "       5.74282303e-01, 6.16620622e-02, 1.11300620e-01, 1.19005061e-02,\n",
       "       1.39228369e-02, 2.50703039e-04, 9.79531703e-01, 4.75933187e-03,\n",
       "       9.78941820e-01, 4.19248106e-01, 6.65326180e-03, 9.83445656e-01,\n",
       "       1.84999542e-02, 7.01828004e-04, 1.12068286e-01, 7.20028762e-01,\n",
       "       1.79367597e-01, 3.20096250e-01, 9.97640781e-01, 1.64292583e-03,\n",
       "       5.68059280e-01, 4.43024130e-02, 9.76273211e-01, 8.75693043e-01,\n",
       "       4.38226702e-03, 9.84245262e-01, 9.35010255e-01, 5.40718361e-02,\n",
       "       7.81218233e-01, 8.98269825e-03, 6.20309295e-02, 4.43115499e-03,\n",
       "       2.29470367e-02, 1.31333675e-02, 9.99991313e-01, 1.92858535e-02,\n",
       "       6.82570702e-01, 3.48707414e-01, 7.47498254e-03, 2.60967674e-01,\n",
       "       9.97373738e-01, 2.78116060e-02, 1.63138070e-02, 9.94161872e-01,\n",
       "       2.14852393e-03, 5.12872594e-01, 8.58105174e-01, 2.07647018e-01,\n",
       "       1.20063857e-01, 5.94957696e-02, 2.40110945e-02, 6.06164070e-01,\n",
       "       7.62533236e-01, 1.52121978e-02, 8.88758140e-01, 1.20694849e-01,\n",
       "       9.71502283e-01, 1.58896262e-03, 1.47783845e-01, 3.43783272e-01,\n",
       "       2.09378715e-02, 9.05118037e-01, 1.62144113e-01, 8.77713011e-03,\n",
       "       1.97140205e-01, 1.57635956e-02, 9.41411435e-01, 8.32811958e-01,\n",
       "       9.97955810e-01, 7.08510385e-01, 9.88234128e-01, 9.46532579e-01,\n",
       "       9.98984502e-01, 3.33945212e-02, 1.07616493e-02, 4.04408233e-01,\n",
       "       9.75464048e-01, 6.21702710e-01, 2.96997809e-01, 6.48180910e-02,\n",
       "       9.55283101e-01, 1.09394443e-03, 7.74047320e-01, 9.98982157e-01,\n",
       "       9.90378491e-01, 9.84857834e-01, 4.16015675e-02, 6.36440236e-03,\n",
       "       2.68711642e-01, 8.91693001e-03, 6.76557389e-02, 3.04525689e-01,\n",
       "       1.40344176e-03, 2.31738989e-02, 3.85156029e-01, 9.82082775e-01,\n",
       "       3.15442020e-02, 4.01922569e-01, 1.81025495e-01, 7.02542126e-01,\n",
       "       9.99978800e-01, 9.98618863e-01, 9.99999389e-01, 4.24174072e-01,\n",
       "       2.33489447e-03, 8.79149294e-01, 8.73318930e-02, 7.89734192e-01,\n",
       "       5.71384263e-02, 9.77453014e-01, 2.19821911e-03, 5.59823690e-01,\n",
       "       9.08815415e-01, 1.68523873e-03, 2.63818749e-03, 2.49140848e-01,\n",
       "       4.67300101e-05, 5.36806894e-01, 3.24744705e-02, 6.21089868e-02,\n",
       "       4.28685624e-03, 5.28905102e-01, 1.90284922e-02, 3.38978236e-03,\n",
       "       5.88628429e-02, 8.13815635e-01, 2.85624751e-02, 6.98129562e-01,\n",
       "       1.84774047e-03, 8.27334316e-01, 2.61970843e-01, 1.37488802e-01,\n",
       "       3.40774354e-02, 9.99834567e-01, 9.98680786e-01, 2.99720262e-01,\n",
       "       5.72473322e-01, 1.59773879e-03, 9.93437497e-01, 1.10217004e-01,\n",
       "       1.14992145e-01, 2.99293225e-02, 1.39209391e-02, 3.75239977e-01,\n",
       "       2.28139812e-01, 4.64423567e-02, 9.97544857e-01, 4.06941098e-03,\n",
       "       9.99574247e-01, 4.57584006e-03, 2.46387956e-01, 4.97603743e-02,\n",
       "       9.75234214e-01, 9.63151759e-02, 2.14819786e-01, 9.99544093e-01,\n",
       "       9.85483053e-03, 8.48129707e-03, 9.87034479e-01, 9.99988657e-01,\n",
       "       2.84015115e-02, 9.99999821e-01, 1.35599105e-02, 3.45129628e-01,\n",
       "       7.06287426e-04, 9.99400726e-01, 7.19536830e-02, 2.60921725e-02,\n",
       "       1.46464372e-02, 1.69622537e-01, 5.95898986e-03, 3.33788961e-02,\n",
       "       2.91753010e-02, 7.99983604e-02, 7.23179348e-01, 9.99904865e-01,\n",
       "       1.13499465e-01, 5.75434813e-03, 8.06562751e-01, 9.92844579e-01,\n",
       "       7.14842241e-01, 3.52184526e-02, 5.06032800e-04, 1.27471063e-01,\n",
       "       3.37830856e-03, 5.45536970e-02, 7.90043627e-01, 9.97484072e-01,\n",
       "       6.69427226e-04])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_tr)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to change the threshold, predicting cell type 1 if the probability of the positive label is greater than 0.85. This now requires a higher confidence compared to using 0.5 as the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False, False,  True, False,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "       False, False, False, False, False,  True, False,  True,  True,\n",
       "       False,  True, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False,  True,  True, False,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False,  True, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "       False,  True, False, False,  True,  True, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_tr)[:,1] > 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measuring Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141,  10],\n",
       "       [ 19,  58]], dtype=int64)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_te, model.predict(x_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute batch of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       151\n",
      "           1       0.85      0.75      0.80        77\n",
      "\n",
      "    accuracy                           0.87       228\n",
      "   macro avg       0.87      0.84      0.85       228\n",
      "weighted avg       0.87      0.87      0.87       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_te, model.predict(x_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics over range of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.87692308 0.890625   0.9047619  0.90322581 0.90163934]\n",
      "\n",
      "recall:    [0.74025974 0.74025974 0.74025974 0.72727273 0.71428571]\n",
      "\n",
      "threshold: [0.52215923 0.53424723 0.54119652 0.55717661 0.56369838]\n"
     ]
    }
   ],
   "source": [
    "# probabilities of positive class from test set\n",
    "pred_pos = model.predict_proba(x_te)[:,1]\n",
    "\n",
    "# calculate metrics over range of thresholds\n",
    "pre, re, th = precision_recall_curve(y_te,  pred_pos)\n",
    "\n",
    "# print metrics for a sample of thresholds\n",
    "print('precision:', pre[100:105])\n",
    "print('')\n",
    "print('recall:   ', re[100:105])\n",
    "print('')\n",
    "print('threshold:', th[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**THINK ABOUT AND DISCUSS**\n",
    "\n",
    "1) If you raise the threshold for predicting a positive label, what generally happens to the recall? What generally happens to the precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "answer: Since we require a higher confidence to predict the positive label, the precision will likely increase.  However, the recall will likely decrease, producing more false negatives. This is why it is important to measure precision and recall together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TRY FOR YOURSELF**\n",
    "\n",
    "You will evaluate the model performance.\n",
    "\n",
    "Hint: you can count the number of rows in a dataframe by using the `len()` function like this: `len(df)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute the accuracy of the model, where accuracy = #correct / #total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "len(df[df['label_predicted'] == df['target']]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Count the number of true positives (where the model predicted 1 and the target is 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "len(df[ (df['label_predicted'] == 1) & (df['target'] == 1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Compute the recall of the model, where precision = #true_positive / #actual_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "len(df[ (df['label_predicted'] == 1) & (df['target'] == 1) ]) / len( df[df['target'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) As we saw earlier, the first subject in the training set has a probability of malignancy = 0.99018766  \n",
    "Compute this by using the intercept, coefficients, f1, f2 values, and the definition of the sigmoid:\n",
    "\n",
    "$sigmoid = 1 / ( 1 + np.exp(-(b0 + b1 * x1 + b2 * x2) ))$\n",
    "\n",
    "Note this version uses two predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99106323])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answer\n",
    "b0 = model.intercept_\n",
    "b1 = model.coef_[0][0]\n",
    "b2 = model.coef_[0][1]\n",
    "x1 = x_tr[0][0]\n",
    "x2 = x_tr[0][1]\n",
    "\n",
    "1 / ( 1 + np.exp(-(b0 + b1 * x1 + b2 * x2) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
