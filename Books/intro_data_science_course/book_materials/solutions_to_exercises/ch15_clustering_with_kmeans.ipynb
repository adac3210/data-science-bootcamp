{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defb5a94-4222-4bd0-8b1a-e12c267e7292",
   "metadata": {},
   "source": [
    "<img src=\"../../predictioNN_Logo_JPG(72).jpg\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603fb86-646b-4121-ae6f-171bc8b79e4f",
   "metadata": {},
   "source": [
    "## Book Solutions\n",
    "### Chapter 15: Clustering with K-Means\n",
    "\n",
    "Last updated: January 14, 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d06935-0397-4cf0-9c6b-8e8bc6e91da4",
   "metadata": {},
   "source": [
    "2. Explain how the k-means algorithm can be used to detect outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438d16a-a41b-406f-aad7-332f74ccb524",
   "metadata": {},
   "source": [
    "Answer: After k-means is fit to data, clusters with a small number of observations (or a singleton observation) may be outliers. These can be investigated further.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb240609-0ca7-4f29-9bce-45123cd02b0e",
   "metadata": {},
   "source": [
    "3. Provide an example of a data pattern that would not be amenable to k-means clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a036e7-d2ce-473c-b9bb-2972b6c7d2b0",
   "metadata": {},
   "source": [
    "Answer: The k-means algorithm uses Euclidean distance for cluster assignment. This works well for spherically-shaped clusters. It would not work well for groups that form concentric circles, for example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c0a4b-8278-4875-976a-764b1d88a401",
   "metadata": {},
   "source": [
    "5. You are deciding on the appropriate value for $k$ when performing k-means clustering. Explain why increasing $k$ until the within-cluster sum of squared errors is minimized is not a good approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51d685-c473-496f-9ff7-77182223e04a",
   "metadata": {},
   "source": [
    "Answer: Increasing $k$ will reduce the within-cluster sum of square errors until each point is its own cluster. This won't provide insight into substructure among the observations. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d394e84-b60e-4349-97a4-5404d8758c64",
   "metadata": {},
   "source": [
    "7. After running k-means with many variables, you notice that the resulting cluster assignments align very closely to one variable in particular. You then realize that you've missed a processing step that led to this variable dominating the others. What is the missing step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6ccce-3716-4a45-a233-3def7c692e23",
   "metadata": {},
   "source": [
    "Answer: If one variable is much more important to the clustering assignment, it is because it is on a larger scale than the others. The missing step is that the variables were not scaled prior to running k-means.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7cbe0-40b6-4354-922a-8ed3894bf8cc",
   "metadata": {},
   "source": [
    "8. To improve the chance of k-means finding the global optimum, the algorithm is run using many different initializations. Why isn't exhaustive search used instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cb0ea-786b-4871-b02b-e46c3be06bf1",
   "metadata": {},
   "source": [
    "Answer: For the case of high-dimensional data, exhaustive search will be computationally prohibitive. This is why random initialization is preferred.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
